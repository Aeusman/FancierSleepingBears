Load processed data
Build dataset
Create corpus dataset
Create training and testing splits
SeqCNNModel(
  (embed): Embedding(12947, 128)
  (conv): ModuleList(
    (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(2,))
    (1): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(2,))
    (2): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(2,))
  )
  (maxpool): MaxPool1d(kernel_size=4, stride=1, padding=1, dilation=1, ceil_mode=False)
  (dropout): Dropout(p=0)
  (output): Linear(in_features=128, out_features=4, bias=True)
)
Epoch: 0 - validation test results - Average val_loss: 0.6820, val_acc: 749/1289.0 (58.11%)
Epoch: 1 - validation test results - Average val_loss: 0.6337, val_acc: 804/1289.0 (62.37%)
Epoch: 2 - validation test results - Average val_loss: 0.5087, val_acc: 979/1289.0 (75.95%)
Epoch: 3 - validation test results - Average val_loss: 0.5871, val_acc: 1044/1289.0 (80.99%)
Epoch: 4 - validation test results - Average val_loss: 0.5661, val_acc: 1085/1289.0 (84.17%)
Epoch: 5 - validation test results - Average val_loss: 0.5367, val_acc: 1087/1289.0 (84.33%)
Epoch: 6 - validation test results - Average val_loss: 0.5902, val_acc: 1101/1289.0 (85.42%)
Epoch: 7 - validation test results - Average val_loss: 0.5866, val_acc: 1111/1289.0 (86.19%)
Epoch: 8 - validation test results - Average val_loss: 0.6417, val_acc: 1121/1289.0 (86.97%)
Epoch: 9 - validation test results - Average val_loss: 0.6781, val_acc: 1124/1289.0 (87.20%)

epoch,acc,loss,val_acc,val_loss

0,0.46731328826639745,17.472562052426582,0.5810706,0.6820219881873061

1,0.554413191203812,0.6837261765357017,0.62373936,0.6337062837173071

2,0.7241513094314664,0.5904376549268671,0.7595035,0.5087316792727071

3,0.8281280310493898,0.39365851023495485,0.8099302,0.587073254344813

4,0.9253152279340446,0.21527257188251306,0.8417378,0.5660905682642946

5,0.9608147429679922,0.12265343744737736,0.8432894,0.5367054717313235

6,0.9759456838136964,0.08102523924567882,0.85415053,0.5901695130128468

7,0.9714839961202716,0.0939567183905889,0.86190844,0.5866172548594449

8,0.9891367604267701,0.04079692310678017,0.8696664,0.64173108353182

9,0.9943743937924345,0.023744318395388736,0.8719938,0.6781403139823162


